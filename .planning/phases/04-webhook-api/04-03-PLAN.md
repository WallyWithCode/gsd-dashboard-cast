---
phase: 04-webhook-api
plan: 03
type: execute
wave: 3
depends_on: ["04-01", "04-02"]
files_modified: [src/api/routes.py, src/main.py, tests/test_api.py]
autonomous: false

must_haves:
  truths:
    - "GET /status returns current stream info or idle"
    - "GET /health checks service and Cast device availability"
    - "Main entrypoint starts uvicorn server"
    - "Webhook endpoints respond correctly to POST requests"
  artifacts:
    - path: "src/api/routes.py"
      provides: "Status and health endpoints"
      contains: "@app.get(\"/status\")"
    - path: "src/main.py"
      provides: "Uvicorn server entrypoint"
      contains: "uvicorn.run"
    - path: "tests/test_api.py"
      provides: "Integration test for webhook flow"
      min_lines: 40
  key_links:
    - from: "/status endpoint"
      to: "StreamTracker.active_tasks"
      via: "read active stream info"
      pattern: "active_tasks"
    - from: "/health endpoint"
      to: "Cast device discovery"
      via: "check if Cast device available"
      pattern: "discover"
    - from: "src/main.py"
      to: "uvicorn server"
      via: "uvicorn.run(app)"
      pattern: "uvicorn\\.run"
---

<objective>
Complete webhook API with status/health endpoints, update main entrypoint, and verify end-to-end flow.

Purpose: Add observability endpoints for monitoring and complete the service integration by updating the main entrypoint to run the FastAPI server, then verify the complete webhook flow works correctly.
Output: Fully functional webhook API with all endpoints tested and verified.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
@./.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-webhook-api/04-RESEARCH.md
@.planning/phases/04-webhook-api/04-CONTEXT.md
@.planning/phases/04-webhook-api/04-01-SUMMARY.md
@.planning/phases/04-webhook-api/04-02-SUMMARY.md

# Cast discovery from Phase 2 - used in health check
@src/cast/discovery.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement /status and /health endpoints</name>
  <files>src/api/routes.py</files>
  <action>
Add status and health endpoints to routes.py following research (04-RESEARCH.md, health check patterns):

```python
from src.api.models import StatusResponse, HealthResponse
from src.cast.discovery import discover_cast_device

def register_routes(app):
    # ... existing /start and /stop ...

    @app.get("/status", response_model=StatusResponse)
    async def get_status():
        """Get current stream status."""
        if not app.state.stream_tracker.has_active_stream():
            return StatusResponse(status="idle", stream=None)

        # Return active stream info
        session_id, task = next(iter(app.state.stream_tracker.active_tasks.items()))

        # TODO: Track stream metadata (started_at, url, quality) in StreamTracker
        # For now, return basic info
        return StatusResponse(
            status="casting",
            stream={
                "session_id": session_id,
                "started_at": "TODO",  # Add timestamp tracking
                "url": "TODO",  # Add metadata tracking
                "quality": "TODO"
            }
        )

    @app.get("/health", response_model=HealthResponse)
    async def health_check():
        """Health check for monitoring."""
        # Check if Cast device is discoverable
        device = await discover_cast_device()
        device_available = device is not None

        status = "healthy" if device_available else "degraded"

        return HealthResponse(
            status=status,
            active_streams=len(app.state.stream_tracker.active_tasks),
            cast_device="available" if device_available else "unavailable"
        )
```

/status returns idle or casting with stream info. /health checks Cast device availability (degraded if device not found). Both use response models for validation.

NOTE: StreamTracker currently doesn't store stream metadata (url, quality, started_at). This is acceptable for v1 - we can enhance in v2 if needed. For now, /status shows session_id only.
  </action>
  <verify>
- routes.py has @app.get("/status") and @app.get("/health")
- Both endpoints return proper response models
  </verify>
  <done>/status and /health endpoints implemented with proper response models</done>
</task>

<task type="auto">
  <name>Task 2: Update main entrypoint to run uvicorn server</name>
  <files>src/main.py, requirements.txt</files>
  <action>
Add uvicorn and fastapi to requirements.txt (versions: fastapi>=0.115.0, uvicorn>=0.32.0).

Update src/main.py to run the FastAPI server:

```python
"""
Dashboard Cast Service
Main entry point - runs the FastAPI webhook API
"""

import uvicorn
from src.api.main import app

if __name__ == "__main__":
    # Run uvicorn server
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
```

Use 0.0.0.0 for Docker compatibility (binds to all interfaces). Port 8000 standard for APIs. uvicorn handles async properly for FastAPI.
  </action>
  <verify>
- requirements.txt contains fastapi and uvicorn
- src/main.py imports app and calls uvicorn.run
- Python can execute: `python -c "from src.main import app"`
  </verify>
  <done>Main entrypoint updated to run uvicorn server on port 8000</done>
</task>

<task type="auto">
  <name>Task 3: Create integration test for webhook flow</name>
  <files>tests/test_api.py</files>
  <action>
Create tests/test_api.py with pytest + httpx for FastAPI testing:

```python
import pytest
from fastapi.testclient import TestClient
from unittest.mock import AsyncMock, patch
from src.api.main import app

@pytest.fixture
def client():
    return TestClient(app)

def test_health_endpoint(client):
    """Health check returns status."""
    with patch("src.cast.discovery.discover_cast_device", return_value=AsyncMock()):
        response = client.get("/health")
        assert response.status_code == 200
        data = response.json()
        assert "status" in data
        assert "active_streams" in data

def test_status_idle(client):
    """Status returns idle when no active stream."""
    response = client.get("/status")
    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "idle"
    assert data["stream"] is None

def test_start_webhook(client):
    """Start webhook accepts request and returns session_id."""
    with patch("src.api.state.StreamManager"):
        response = client.post("/start", json={
            "url": "https://example.com",
            "quality": "1080p",
            "duration": 300
        })
        assert response.status_code == 200
        data = response.json()
        assert data["status"] == "success"
        assert "session_id" in data

def test_stop_webhook(client):
    """Stop webhook accepts request."""
    response = client.post("/stop")
    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "success"

def test_start_invalid_url(client):
    """Start webhook rejects invalid URL."""
    response = client.post("/start", json={
        "url": "not-a-url",
        "quality": "1080p"
    })
    assert response.status_code == 422  # Pydantic validation error
```

Use TestClient for sync testing (FastAPI handles async internally). Mock StreamManager to avoid actual streaming. Mock Cast discovery for health check. Test all endpoints + validation.

Add pytest to requirements.txt if not present.
  </action>
  <verify>
- tests/test_api.py exists
- Can run: `pytest tests/test_api.py -v`
- All tests pass (or skip if dependencies missing)
  </verify>
  <done>Integration tests verify all webhook endpoints work correctly</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete webhook API with /start, /stop, /status, /health endpoints</what-built>
  <how-to-verify>
1. Start the service: `python src/main.py`
2. In another terminal, test endpoints with curl:

   Health check:
   ```bash
   curl http://localhost:8000/health
   # Should return: {"status": "healthy" or "degraded", "active_streams": 0, "cast_device": "..."}
   ```

   Status (idle):
   ```bash
   curl http://localhost:8000/status
   # Should return: {"status": "idle", "stream": null}
   ```

   Start webhook:
   ```bash
   curl -X POST http://localhost:8000/start \
     -H "Content-Type: application/json" \
     -d '{"url": "https://example.com", "quality": "1080p", "duration": 10}'
   # Should return: {"status": "success", "session_id": "..."}
   # Should see structured JSON logs in terminal
   ```

   Status (casting):
   ```bash
   curl http://localhost:8000/status
   # Should return: {"status": "casting", "stream": {...}}
   ```

   Stop webhook:
   ```bash
   curl -X POST http://localhost:8000/stop
   # Should return: {"status": "success", "message": "Stream stopped"}
   ```

3. Verify in logs:
   - All webhook events logged as JSON
   - session_id, url, quality visible in log context
   - Timestamps in ISO format

4. Check graceful shutdown:
   - Ctrl+C the server
   - Should see "app_shutdown" log with active stream cleanup
   - No hanging processes
  </how-to-verify>
  <resume-signal>Type "approved" if all endpoints work and logs are structured, or describe issues</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] /status and /health endpoints defined
- [ ] Main entrypoint runs uvicorn server
- [ ] Integration tests exist and pass
- [ ] Manual testing confirms endpoints work
- [ ] Structured logs visible in JSON format
</verification>

<success_criteria>
- All tasks completed
- Status and health endpoints return proper responses
- Main entrypoint starts FastAPI server on port 8000
- Integration tests verify webhook flow
- User confirmed endpoints work correctly via curl
- Phase 4 complete: Webhook API functional and verified
</success_criteria>

<output>
After completion, create `.planning/phases/04-webhook-api/04-03-SUMMARY.md`
</output>
