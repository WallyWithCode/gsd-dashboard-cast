---
phase: 10-intel-quicksync-hardware-acceleration
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - docs/PROXMOX_GPU_PASSTHROUGH.md
autonomous: false

must_haves:
  truths:
    - User can enable GPU passthrough in Proxmox following step-by-step guide
    - Documentation covers IOMMU enablement, device identification, and container configuration
    - Guide includes verification steps to confirm /dev/dri access
  artifacts:
    - path: docs/PROXMOX_GPU_PASSTHROUGH.md
      provides: Proxmox GPU passthrough configuration guide
      min_lines: 150
  key_links:
    - from: docs/PROXMOX_GPU_PASSTHROUGH.md
      to: GRUB configuration
      via: IOMMU kernel parameters
      pattern: "intel_iommu=on"
    - from: docs/PROXMOX_GPU_PASSTHROUGH.md
      to: /dev/dri verification
      via: vainfo command
      pattern: "vainfo"
---

<objective>
Create comprehensive documentation for enabling Intel GPU passthrough in Proxmox to provide /dev/dri device access to Docker containers running in VMs or LXC.

Purpose: Enables users to configure Proxmox environment for QuickSync hardware acceleration, required for /dev/dri/renderD128 access
Output: Step-by-step guide covering IOMMU setup, device passthrough, and verification
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-intel-quicksync-hardware-acceleration/10-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Create Proxmox GPU passthrough documentation</name>
  <files>docs/PROXMOX_GPU_PASSTHROUGH.md</files>
  <action>
Create comprehensive guide for enabling Intel QuickSync in Proxmox environments.

Structure:
```markdown
# Proxmox Intel QuickSync GPU Passthrough Guide

## Overview

This guide enables Intel QuickSync hardware acceleration for the Dashboard Cast Service running in Proxmox VMs or LXC containers. QuickSync reduces CPU usage by 80-90% per stream by offloading H.264 encoding to the Intel integrated GPU.

**Requirements:**
- Proxmox VE 7.0+ (tested on 8.2.7)
- Intel CPU with integrated graphics (NOT "F" suffix models like i9-14900KF)
- Intel Gen 8+ CPU recommended (Broadwell 2014+) for iHD driver support

## Deployment Options

### Option 1: LXC Container (Recommended)

Simpler setup, better performance, privileged container required for device access.

### Option 2: VM with GPU Passthrough

More complex setup, requires IOMMU/VT-d, use if LXC not suitable.

---

## LXC Container Setup (Recommended)

### Step 1: Enable IOMMU in Proxmox Host

Even LXC containers require IOMMU enabled for GPU device access.

1. Check CPU support:
```bash
dmesg | grep -e DMAR -e IOMMU
# Should show: "DMAR: IOMMU enabled" or similar
```

2. Edit GRUB configuration on Proxmox host:
```bash
nano /etc/default/grub
```

3. Add IOMMU parameters to GRUB_CMDLINE_LINUX_DEFAULT:
```
GRUB_CMDLINE_LINUX_DEFAULT="quiet intel_iommu=on iommu=pt"
```

4. Update GRUB and reboot:
```bash
update-grub
reboot
```

5. Verify after reboot:
```bash
dmesg | grep -e DMAR -e IOMMU
# Should show "IOMMU enabled"
```

### Step 2: Identify GPU Device

On Proxmox host, identify Intel GPU device:

```bash
ls -l /dev/dri/
# Look for: renderD128 (render node for encoding)
# May also see: card0 (display output)
```

Note the major:minor device numbers (usually 226:128 for renderD128).

### Step 3: Configure LXC Container

1. Edit container config on Proxmox host:
```bash
nano /etc/pve/lxc/<CTID>.conf
```

2. Add device passthrough lines:
```
lxc.cgroup2.devices.allow: c 226:0 rwm
lxc.cgroup2.devices.allow: c 226:128 rwm
lxc.mount.entry: /dev/dri/card0 dev/dri/card0 none bind,optional,create=file
lxc.mount.entry: /dev/dri/renderD128 dev/dri/renderD128 none bind,optional,create=file
```

3. Restart container:
```bash
pct stop <CTID>
pct start <CTID>
```

### Step 4: Configure Groups Inside Container

Enter container and set up permissions:

```bash
pct enter <CTID>

# Check if /dev/dri exists
ls -l /dev/dri

# Get render and video group IDs using helper script
cd /path/to/dashboard-cast
scripts/detect-gpu-gids.sh

# Update docker-compose.yml with actual GIDs:
# Replace RENDER_GID with the number from render group
# Replace VIDEO_GID with the number from video group
```

### Step 5: Install Drivers in Container

Inside container (or rebuild Docker image):

```bash
apt-get update
apt-get install -y \
    intel-media-va-driver-non-free \
    vainfo \
    libva2 \
    libva-drm2
```

### Step 6: Verify Hardware Access

Inside container:

```bash
# Check VAAPI driver loads
vainfo --display drm --device /dev/dri/renderD128

# Expected output includes:
# - Driver version: Intel iHD driver
# - VAProfileH264High : VAEntrypointEncSlice

# Check FFmpeg recognizes encoder
ffmpeg -encoders | grep h264_qsv

# Expected: h264_qsv (H.264 / AVC ... Intel Quick Sync Video acceleration)
```

---

## VM Setup (Alternative)

### Step 1-2: Enable IOMMU (Same as LXC)

Follow LXC Step 1 for IOMMU enablement.

### Step 3: Identify IOMMU Group

```bash
# On Proxmox host
find /sys/kernel/iommu_groups/ -type l | grep -i vga
# Note the IOMMU group number
```

### Step 4: Configure VM for PCI Passthrough

1. In Proxmox web UI: VM > Hardware > Add > PCI Device
2. Select Intel VGA device
3. Enable: All Functions, Primary GPU (if applicable)
4. Restart VM

### Step 5: Install Drivers in VM (Same as LXC Step 5-6)

Follow LXC steps 5-6 inside the VM.

---

## Troubleshooting

### /dev/dri does not exist

**Cause:** IOMMU not enabled, or device not passed through.

**Fix:**
- Verify IOMMU enabled: `dmesg | grep IOMMU`
- Check LXC config has lxc.mount.entry lines
- Restart container: `pct stop <CTID> && pct start <CTID>`

### Permission denied on /dev/dri/renderD128

**Cause:** Container user not in render/video groups.

**Fix:**
- Inside container: `ls -l /dev/dri/renderD128` (check group ownership)
- Run scripts/detect-gpu-gids.sh to get correct GIDs
- Update docker-compose.yml group_add with correct GIDs
- Rebuild container: `docker-compose down && docker-compose up -d`

### vainfo shows i965 driver instead of iHD

**Cause:** Wrong driver selected (i965 is legacy, archived 2025).

**Fix:**
- Set environment variable in docker-compose.yml: `LIBVA_DRIVER_NAME=iHD`
- Verify: `vainfo | grep "Driver version"` should show "iHD"

### h264_qsv not found in ffmpeg -encoders

**Cause:** FFmpeg package doesn't include QSV support, or drivers missing.

**Fix:**
- Ensure intel-media-va-driver-non-free installed
- Check Debian/Ubuntu FFmpeg package includes --enable-vaapi
- Verify: `ffmpeg -hwaccels` should list "qsv"

### CPU has "F" suffix (e.g., i9-14900KF)

**Cause:** "F" models lack integrated graphics.

**Fix:** QuickSync requires integrated GPU. Use non-F model CPU (e.g., i9-14900K).

---

## Verification Checklist

After setup, verify all components:

- [ ] IOMMU enabled: `dmesg | grep IOMMU` shows "enabled"
- [ ] /dev/dri exists in container: `ls -l /dev/dri`
- [ ] vainfo succeeds: `vainfo --display drm --device /dev/dri/renderD128`
- [ ] vainfo shows iHD driver (not i965)
- [ ] vainfo shows VAEntrypointEncSlice for H264High profile
- [ ] h264_qsv in ffmpeg: `ffmpeg -encoders | grep h264_qsv`
- [ ] Health endpoint reports QuickSync: `curl http://localhost:8000/health | jq .hardware_acceleration`

---

## References

- [Proxmox PCI Passthrough Wiki](https://pve.proxmox.com/wiki/PCI_Passthrough)
- [FFmpeg Hardware/QuickSync Wiki](https://trac.ffmpeg.org/wiki/Hardware/QuickSync)
- [Jellyfin Intel GPU HWA Guide](https://jellyfin.org/docs/general/administration/hardware-acceleration/intel/)
- Project research: `.planning/phases/10-intel-quicksync-hardware-acceleration/10-RESEARCH.md`

---

*Guide created: 2026-01-19*
*Tested on: Proxmox VE 8.2.7 with Intel CPUs Gen 8+*
```

Create docs/ directory if it doesn't exist.

Reference: RESEARCH.md "Common Pitfalls" section, particularly:
- Pitfall 2: Permission denied (render/video groups)
- Pitfall 3: Driver conflict (i965 vs iHD)
- Pitfall 5: IOMMU not enabled
- Open Question 1: LXC vs VM passthrough approaches

DO NOT include NVIDIA or AMD GPU instructions (out of scope for Phase 10).
DO NOT include deprecated i965 driver setup (archived Jan 2025).
  </action>
  <verify>
test -f docs/PROXMOX_GPU_PASSTHROUGH.md && wc -l docs/PROXMOX_GPU_PASSTHROUGH.md | awk '{print ($1 >= 150) ? "PASS: Document has sufficient detail" : "FAIL: Document too short"}'
grep -q "intel_iommu=on" docs/PROXMOX_GPU_PASSTHROUGH.md && echo "PASS: IOMMU config included"
grep -q "lxc.mount.entry" docs/PROXMOX_GPU_PASSTHROUGH.md && echo "PASS: LXC passthrough included"
  </verify>
  <done>docs/PROXMOX_GPU_PASSTHROUGH.md exists with 150+ lines covering IOMMU setup, LXC container passthrough, VM passthrough, driver installation, and troubleshooting</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete Phase 10 implementation:
- Docker infrastructure with Intel media drivers (Plan 10-01)
- Hardware detection module with graceful fallback (Plan 10-02)
- Encoder integration with h264_qsv support (Plan 10-03)
- Proxmox GPU passthrough documentation (Plan 10-04)
  </what-built>
  <how-to-verify>
**Step 1: Build and verify Docker image**
```bash
cd /root/claudeProjects/WSL/gsd-dashboard-cast
docker build -t dashboard-cast:qsv .
docker run --rm dashboard-cast:qsv ffmpeg -encoders 2>/dev/null | grep h264_qsv
# Expected: h264_qsv encoder listed
```

**Step 2: Test hardware detection (software fallback)**
```bash
docker run --rm dashboard-cast:qsv python3 -c "from src.video.hardware import HardwareAcceleration; hw = HardwareAcceleration(); print(f'QSV: {hw.is_qsv_available()}, Encoder: {hw.get_encoder_config()[\"encoder\"]}')"
# Expected: QSV: False, Encoder: libx264 (no GPU passthrough yet)
```

**Step 3: Check health endpoint reports hardware status**
```bash
# Start service
docker-compose up -d
sleep 5

# Query health endpoint
curl http://localhost:8000/health | jq .
# Expected JSON includes:
# "hardware_acceleration": {
#   "quicksync_available": false,
#   "encoder": "libx264"
# }
```

**Step 4: Test encoding with software fallback**
```bash
# Trigger a cast (this will use libx264 software encoding without GPU passthrough)
curl -X POST http://localhost:8000/start \
  -H "Content-Type: application/json" \
  -d '{"url": "http://example.com", "quality": "720p", "duration": 10}'

# Monitor logs for encoder confirmation
docker logs dashboard-cast 2>&1 | grep "Starting FFmpeg encoder"
# Expected: "Starting FFmpeg encoder: libx264 @ ..."

# Stop after test
curl -X POST http://localhost:8000/stop
docker-compose down
```

**Step 5: (REQUIRED FOR HWAC-04) Test QuickSync hardware acceleration**

**NOTE:** This step verifies HWAC-04 (80-90% CPU reduction). At least ONE scenario with actual hardware must be tested to validate the requirement. If Proxmox GPU passthrough is not available in current environment, this validation is deferred to production deployment.

If you have access to Proxmox host with Intel GPU:

1. Follow docs/PROXMOX_GPU_PASSTHROUGH.md guide to configure GPU passthrough
2. Run `scripts/detect-gpu-gids.sh` to get render and video GIDs
3. Update docker-compose.yml group_add with actual GIDs (replace RENDER_GID and VIDEO_GID placeholders)
4. Restart service: `docker-compose down && docker-compose up -d`
5. Verify QuickSync available:
   ```bash
   curl http://localhost:8000/health | jq .hardware_acceleration
   # Expected: "quicksync_available": true, "encoder": "h264_qsv"
   ```

6. **Measure CPU usage with libx264 (software encoding):**
   ```bash
   # Force software encoding by temporarily removing /dev/dri from docker-compose.yml
   # or setting LIBVA_DRIVER_NAME=none

   # Start a cast
   curl -X POST http://localhost:8000/start \
     -H "Content-Type: application/json" \
     -d '{"url": "http://example.com", "quality": "720p", "duration": 60}'

   # Measure CPU usage (in separate terminal)
   docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}" dashboard-cast
   # Note the CPU% value (e.g., 45.2%)

   # Stop cast
   curl -X POST http://localhost:8000/stop
   ```

7. **Measure CPU usage with h264_qsv (hardware encoding):**
   ```bash
   # Re-enable /dev/dri passthrough in docker-compose.yml
   docker-compose down && docker-compose up -d

   # Start same cast
   curl -X POST http://localhost:8000/start \
     -H "Content-Type: application/json" \
     -d '{"url": "http://example.com", "quality": "720p", "duration": 60}'

   # Measure CPU usage (in separate terminal)
   docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}" dashboard-cast
   # Note the CPU% value (e.g., 4.8%)

   # Stop cast
   curl -X POST http://localhost:8000/stop
   ```

8. **Calculate CPU reduction:**
   ```
   Reduction = ((libx264_cpu - h264_qsv_cpu) / libx264_cpu) * 100
   Example: ((45.2 - 4.8) / 45.2) * 100 = 89.4% reduction

   PASS if reduction >= 80%
   ```

**If Proxmox/GPU access not available:** Acknowledge that HWAC-04 validation is deferred to production environment. Steps 1-4 confirm graceful fallback works correctly.
  </how-to-verify>
  <resume-signal>
Confirm verification results:

**Required (software fallback validation):**
1. "docker build succeeds" - h264_qsv encoder present in image
2. "fallback works" - Hardware detection returns libx264 when no GPU
3. "health endpoint works" - Reports hardware_acceleration status
4. "encoding works" - Service starts stream with libx264 software encoding

**Required for HWAC-04 (if hardware available):**
5. "quicksync works" - Health endpoint reports quicksync_available: true
6. "cpu reduced 80-90%" - Measured CPU% reduction with h264_qsv vs libx264

**OR:**
- "hardware validation deferred" - No Proxmox/GPU access, HWAC-04 validation deferred to production

Describe any issues encountered or provide CPU measurement results.
  </resume-signal>
</task>

</tasks>

<verification>
Overall verification:
- docs/PROXMOX_GPU_PASSTHROUGH.md created with comprehensive guide
- Guide covers both LXC and VM passthrough approaches
- Includes IOMMU configuration, device identification, driver installation
- Troubleshooting section addresses common pitfalls from research
- Human verified complete phase implementation works correctly
- (Optional) Human verified HWAC-04 CPU reduction with actual hardware or acknowledged deferral
</verification>

<success_criteria>
- Proxmox GPU passthrough guide exists with 150+ lines
- Guide covers IOMMU enablement (intel_iommu=on kernel parameter)
- Guide covers LXC container device passthrough (lxc.mount.entry configuration)
- Guide covers VM PCI passthrough approach
- Guide includes driver installation steps (intel-media-va-driver-non-free)
- Guide includes verification steps (vainfo, ffmpeg -encoders)
- Troubleshooting section covers permission issues, driver selection, and common errors
- Human verified end-to-end functionality (software fallback works correctly)
- Human verified HWAC-04 CPU reduction with actual hardware OR acknowledged deferral to production
</success_criteria>

<output>
After completion, create `.planning/phases/10-intel-quicksync-hardware-acceleration/10-04-SUMMARY.md`
</output>
